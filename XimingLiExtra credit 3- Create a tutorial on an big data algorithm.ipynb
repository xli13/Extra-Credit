{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K-nearest neighbors (KNN) algorithm is a type of supervised machine learning algorithms. KNN is extremely easy to implement in its most basic form, and yet performs quite complex classification tasks. Rather, it uses all of the data for training while classifying a new data point or instance.\n",
    "KNN can be used for both classification and regression predictive problems. However, it is more widely used in classification problems in the industry. To evaluate any technique we generally look at 3 important aspects:\n",
    "1. Ease to interpret output 2. Calculation time 3. Predictive Power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement a KNN model by following the below steps:\n",
    "\n",
    "1. Load the data\n",
    "2. Initialise the value of k. \n",
    "3. For getting the predicted class, iterate from 1 to total number of training data points (1) Calculate the distance between test data and each row of training data. Here we will use Euclidean distance as our distance metric since itâ€™s the most popular method. The other metrics that can be used are Chebyshev, cosine, etc.\n",
    "(2)Sort the calculated distances in ascending order based on distance values\n",
    "(3)Get top k rows from the sorted array\n",
    "(4)Get the most frequent class of these rows\n",
    "(5)Return the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        Class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Start of STEP 1\n",
    "# Importing data \n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "data = pd.read_csv(url, names=names) \n",
    "data.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# Defining a function which calculates euclidean distance between two data points\n",
    "def euclideanDistance(data1, data2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += np.square(data1[x] - data2[x])\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "# Defining our KNN model\n",
    "def knn(trainingSet, testInstance, k):\n",
    " \n",
    "    distances = {}\n",
    "    sort = {}\n",
    " \n",
    "    length = testInstance.shape[1]\n",
    "    \n",
    "    #STEP 3\n",
    "    # Calculating euclidean distance between each row of training data and test data\n",
    "    for x in range(len(trainingSet)):\n",
    "        \n",
    "        #STEP 3.1\n",
    "        dist = euclideanDistance(testInstance, trainingSet.iloc[x], length)\n",
    "\n",
    "        distances[x] = dist[0]\n",
    "        \n",
    " \n",
    "    #STEP 3.2\n",
    "    #Sorting them on the basis of distance\n",
    "    sorted_d = sorted(distances.items(), key=operator.itemgetter(1))\n",
    "    \n",
    " \n",
    "    neighbors = []\n",
    "    \n",
    "    #STEP 3.3\n",
    "    #Extracting top k neighbors\n",
    "    for x in range(k):\n",
    "        neighbors.append(sorted_d[x][0])\n",
    "    \n",
    "    classVotes = {}\n",
    "    \n",
    "    #STEP 3.4\n",
    "    # Calculating the most freq class in the neighbors\n",
    "    for x in range(len(neighbors)):\n",
    "        response = trainingSet.iloc[neighbors[x]][-1]\n",
    " \n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    \n",
    "\n",
    "    #STEP 3.5\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return(sortedVotes[0][0], neighbors)\n",
    "    \n",
    "\n",
    "\n",
    "# Creating a dummy testset\n",
    "testSet = [[7.2, 3.6, 5.1, 2.5]]\n",
    "test = pd.DataFrame(testSet)\n",
    "#Start of STEP 2\n",
    "# Setting number of neighbors = 1\n",
    "k = 1\n",
    "\n",
    "# Running KNN model\n",
    "result,neigh = knn(data, test, k)\n",
    "\n",
    "# Predicted class\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141]\n"
     ]
    }
   ],
   "source": [
    "# Nearest neighbor\n",
    "print(neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to alter the k values, and see how the prediction changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# Setting number of neighbors = 3 \n",
    "k = 3 \n",
    "# Running KNN model \n",
    "result,neigh = knn(data, test, k) \n",
    "# Predicted class \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141, 139, 120]\n"
     ]
    }
   ],
   "source": [
    "# 3 nearest neighbors\n",
    "print(neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# Setting number of neighbors = 5\n",
    "k = 5\n",
    "# Running KNN model \n",
    "result,neigh = knn(data, test, k) \n",
    "# Predicted class \n",
    "print(result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141, 139, 120, 145, 144]\n"
     ]
    }
   ],
   "source": [
    "# 5 nearest neighbors\n",
    "print(neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing our model with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(data.iloc[:,0:4], data['Class'])\n",
    "\n",
    "# Predicted class\n",
    "print(neigh.predict(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141 139 120]]\n"
     ]
    }
   ],
   "source": [
    "# 3 nearest neighbors\n",
    "print(neigh.kneighbors(test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both the models predicted the same class (â€˜Iris-virginicaâ€™) and the same nearest neighbors ( [141 139 120] ). Hence we can conclude that our model runs as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN algorithm is one of the simplest classification algorithm. Even with such simplicity, it can give highly competitive results. KNN algorithm can also be used for regression problems. The only difference from the discussed methodology will be using averages of nearest neighbors rather than voting from nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
